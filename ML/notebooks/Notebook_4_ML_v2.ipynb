{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f65a1ca-fbc1-49b0-83f4-88bed03099f4",
   "metadata": {},
   "source": [
    "From the previous notebook, the features present in the dataset was not sufficient, and thus the macro avg was lower. So we now expand the features in the same dataset in order to increase the f1 score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2268e9-f516-428b-a276-42b59832ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174b83ca-b71a-4858-86b7-08789b170853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading dataset\n",
    "df = pd.read_csv(r\"E:\\major_project\\datasets\\password_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc60f33c-f26e-4adf-895e-d5297fcd8211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>password</th>\n",
       "      <th>length</th>\n",
       "      <th>bucket</th>\n",
       "      <th>strength</th>\n",
       "      <th>lowercase_count</th>\n",
       "      <th>uppercase_count</th>\n",
       "      <th>special_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>has_special</th>\n",
       "      <th>has_digit</th>\n",
       "      <th>unique_chars</th>\n",
       "      <th>char_diversity</th>\n",
       "      <th>entropy</th>\n",
       "      <th>seq_letters</th>\n",
       "      <th>max_repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>agus</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>roar</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>malz</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cuba</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pcms</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 password  length bucket  strength  lowercase_count  \\\n",
       "0           0     agus       4    0-4       1.0                4   \n",
       "1           1     roar       4    0-4       1.0                4   \n",
       "2           2     malz       4    0-4       1.0                4   \n",
       "3           3     cuba       4    0-4       1.0                4   \n",
       "4           4     pcms       4    0-4       1.0                4   \n",
       "\n",
       "   uppercase_count  special_count  digit_count  has_special  has_digit  \\\n",
       "0                0              0            4            0          1   \n",
       "1                0              0            4            0          1   \n",
       "2                0              0            4            0          1   \n",
       "3                0              0            4            0          1   \n",
       "4                0              0            4            0          1   \n",
       "\n",
       "   unique_chars  char_diversity  entropy  seq_letters  max_repeat  \n",
       "0             4               2      2.0            0           1  \n",
       "1             3               2      1.5            0           1  \n",
       "2             4               2      2.0            0           1  \n",
       "3             4               2      2.0            0           1  \n",
       "4             4               2      2.0            0           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0e419e-cf3a-4e3d-a874-6796b23dfc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299661 entries, 0 to 299660\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   Unnamed: 0       299661 non-null  int64  \n",
      " 1   password         299661 non-null  object \n",
      " 2   length           299661 non-null  int64  \n",
      " 3   bucket           299661 non-null  object \n",
      " 4   strength         299661 non-null  float64\n",
      " 5   lowercase_count  299661 non-null  int64  \n",
      " 6   uppercase_count  299661 non-null  int64  \n",
      " 7   special_count    299661 non-null  int64  \n",
      " 8   digit_count      299661 non-null  int64  \n",
      " 9   has_special      299661 non-null  int64  \n",
      " 10  has_digit        299661 non-null  int64  \n",
      " 11  unique_chars     299661 non-null  int64  \n",
      " 12  char_diversity   299661 non-null  int64  \n",
      " 13  entropy          299661 non-null  float64\n",
      " 14  seq_letters      299661 non-null  int64  \n",
      " 15  max_repeat       299661 non-null  int64  \n",
      "dtypes: float64(2), int64(12), object(2)\n",
      "memory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9114c8-f31c-47cf-9676-776832df0eb7",
   "metadata": {},
   "source": [
    "## Adding and updating features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e8ca9-ffd6-4404-ad06-ace0de04bdf6",
   "metadata": {},
   "source": [
    "From looking at previous notebook, I found a wrong logic while adding the column \"digit_count\" which counted alphabet instead of numbers. In this section, we will change it. Similarly, we will add additional features to supplement the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b35a4b6-528b-43f4-a261-7a1ca66064cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating digit_count\n",
    "df['digit_count'] = df[\"password\"].str.count(r'[0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7732988-1c95-4c70-9a52-50568fcdeda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>password</th>\n",
       "      <th>length</th>\n",
       "      <th>bucket</th>\n",
       "      <th>strength</th>\n",
       "      <th>lowercase_count</th>\n",
       "      <th>uppercase_count</th>\n",
       "      <th>special_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>has_special</th>\n",
       "      <th>has_digit</th>\n",
       "      <th>unique_chars</th>\n",
       "      <th>char_diversity</th>\n",
       "      <th>entropy</th>\n",
       "      <th>seq_letters</th>\n",
       "      <th>max_repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>agus</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>roar</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>malz</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cuba</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pcms</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299656</th>\n",
       "      <td>299995</td>\n",
       "      <td>changepassword___</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3.572469</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299657</th>\n",
       "      <td>299996</td>\n",
       "      <td>stupidmotherfucker</td>\n",
       "      <td>18</td>\n",
       "      <td>17+</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.725481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299658</th>\n",
       "      <td>299997</td>\n",
       "      <td>luistekelounresto</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3.219528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299659</th>\n",
       "      <td>299998</td>\n",
       "      <td>themontles@yahoo.com</td>\n",
       "      <td>20</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3.521928</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299660</th>\n",
       "      <td>299999</td>\n",
       "      <td>secilandralph7497</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.734522</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299661 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0              password  length bucket  strength  \\\n",
       "0                0                  agus       4    0-4       1.0   \n",
       "1                1                  roar       4    0-4       1.0   \n",
       "2                2                  malz       4    0-4       1.0   \n",
       "3                3                  cuba       4    0-4       1.0   \n",
       "4                4                  pcms       4    0-4       1.0   \n",
       "...            ...                   ...     ...    ...       ...   \n",
       "299656      299995     changepassword___      17    17+       3.0   \n",
       "299657      299996    stupidmotherfucker      18    17+       2.0   \n",
       "299658      299997     luistekelounresto      17    17+       4.0   \n",
       "299659      299998  themontles@yahoo.com      20    17+       4.0   \n",
       "299660      299999     secilandralph7497      17    17+       4.0   \n",
       "\n",
       "        lowercase_count  uppercase_count  special_count  digit_count  \\\n",
       "0                     4                0              0            0   \n",
       "1                     4                0              0            0   \n",
       "2                     4                0              0            0   \n",
       "3                     4                0              0            0   \n",
       "4                     4                0              0            0   \n",
       "...                 ...              ...            ...          ...   \n",
       "299656               14                0              3            0   \n",
       "299657               18                0              0            0   \n",
       "299658               17                0              0            0   \n",
       "299659               18                0              2            0   \n",
       "299660               13                0              0            4   \n",
       "\n",
       "        has_special  has_digit  unique_chars  char_diversity   entropy  \\\n",
       "0                 0          1             4               2  2.000000   \n",
       "1                 0          1             3               2  1.500000   \n",
       "2                 0          1             4               2  2.000000   \n",
       "3                 0          1             4               2  2.000000   \n",
       "4                 0          1             4               2  2.000000   \n",
       "...             ...        ...           ...             ...       ...   \n",
       "299656            1          1            13               3  3.572469   \n",
       "299657            0          1            14               2  3.725481   \n",
       "299658            0          1            10               2  3.219528   \n",
       "299659            1          1            13               3  3.521928   \n",
       "299660            0          1            14               2  3.734522   \n",
       "\n",
       "        seq_letters  max_repeat  \n",
       "0                 0           1  \n",
       "1                 0           1  \n",
       "2                 0           1  \n",
       "3                 0           1  \n",
       "4                 0           1  \n",
       "...             ...         ...  \n",
       "299656            1           3  \n",
       "299657            1           1  \n",
       "299658            0           1  \n",
       "299659            0           2  \n",
       "299660            0           1  \n",
       "\n",
       "[299661 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334164d2-80b1-4580-b783-67291acd9283",
   "metadata": {},
   "source": [
    "After correcting the digit_count, we will add ratio features ( divided by length), which is better for trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "921ad766-af85-4c09-af40-a554f0280165",
   "metadata": {},
   "outputs": [],
   "source": [
    "##normalization for password containing certain digits\n",
    "df[\"digit_ratio\"] = df[\"digit_count\"] / df[\"length\"]\n",
    "\n",
    "#normalized value for passwords with special characters\n",
    "df[\"special_ratio\"] = df[\"special_count\"] / df[\"length\"]\n",
    "\n",
    "#normalized value for characters containing unique no. of characters((explained in notebook 2)\n",
    "df[\"unique_ratio\"] = df[\"unique_chars\"] / df[\"length\"]\n",
    "\n",
    "#normalization of entropy\n",
    "df[\"entropy_norm\"]=df[\"entropy\"]/df[\"length\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1388cd61-4acc-4cb4-bdb1-eefe41de24be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>password</th>\n",
       "      <th>length</th>\n",
       "      <th>bucket</th>\n",
       "      <th>strength</th>\n",
       "      <th>lowercase_count</th>\n",
       "      <th>uppercase_count</th>\n",
       "      <th>special_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>has_special</th>\n",
       "      <th>has_digit</th>\n",
       "      <th>unique_chars</th>\n",
       "      <th>char_diversity</th>\n",
       "      <th>entropy</th>\n",
       "      <th>seq_letters</th>\n",
       "      <th>max_repeat</th>\n",
       "      <th>digit_ratio</th>\n",
       "      <th>special_ratio</th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>entropy_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>agus</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>roar</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>malz</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cuba</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pcms</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299656</th>\n",
       "      <td>299995</td>\n",
       "      <td>changepassword___</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3.572469</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.210145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299657</th>\n",
       "      <td>299996</td>\n",
       "      <td>stupidmotherfucker</td>\n",
       "      <td>18</td>\n",
       "      <td>17+</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.725481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.206971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299658</th>\n",
       "      <td>299997</td>\n",
       "      <td>luistekelounresto</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3.219528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.189384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299659</th>\n",
       "      <td>299998</td>\n",
       "      <td>themontles@yahoo.com</td>\n",
       "      <td>20</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3.521928</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.176096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299660</th>\n",
       "      <td>299999</td>\n",
       "      <td>secilandralph7497</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.734522</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.219678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299661 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0              password  length bucket  strength  \\\n",
       "0                0                  agus       4    0-4       1.0   \n",
       "1                1                  roar       4    0-4       1.0   \n",
       "2                2                  malz       4    0-4       1.0   \n",
       "3                3                  cuba       4    0-4       1.0   \n",
       "4                4                  pcms       4    0-4       1.0   \n",
       "...            ...                   ...     ...    ...       ...   \n",
       "299656      299995     changepassword___      17    17+       3.0   \n",
       "299657      299996    stupidmotherfucker      18    17+       2.0   \n",
       "299658      299997     luistekelounresto      17    17+       4.0   \n",
       "299659      299998  themontles@yahoo.com      20    17+       4.0   \n",
       "299660      299999     secilandralph7497      17    17+       4.0   \n",
       "\n",
       "        lowercase_count  uppercase_count  special_count  digit_count  \\\n",
       "0                     4                0              0            0   \n",
       "1                     4                0              0            0   \n",
       "2                     4                0              0            0   \n",
       "3                     4                0              0            0   \n",
       "4                     4                0              0            0   \n",
       "...                 ...              ...            ...          ...   \n",
       "299656               14                0              3            0   \n",
       "299657               18                0              0            0   \n",
       "299658               17                0              0            0   \n",
       "299659               18                0              2            0   \n",
       "299660               13                0              0            4   \n",
       "\n",
       "        has_special  has_digit  unique_chars  char_diversity   entropy  \\\n",
       "0                 0          1             4               2  2.000000   \n",
       "1                 0          1             3               2  1.500000   \n",
       "2                 0          1             4               2  2.000000   \n",
       "3                 0          1             4               2  2.000000   \n",
       "4                 0          1             4               2  2.000000   \n",
       "...             ...        ...           ...             ...       ...   \n",
       "299656            1          1            13               3  3.572469   \n",
       "299657            0          1            14               2  3.725481   \n",
       "299658            0          1            10               2  3.219528   \n",
       "299659            1          1            13               3  3.521928   \n",
       "299660            0          1            14               2  3.734522   \n",
       "\n",
       "        seq_letters  max_repeat  digit_ratio  special_ratio  unique_ratio  \\\n",
       "0                 0           1     0.000000       0.000000      1.000000   \n",
       "1                 0           1     0.000000       0.000000      0.750000   \n",
       "2                 0           1     0.000000       0.000000      1.000000   \n",
       "3                 0           1     0.000000       0.000000      1.000000   \n",
       "4                 0           1     0.000000       0.000000      1.000000   \n",
       "...             ...         ...          ...            ...           ...   \n",
       "299656            1           3     0.000000       0.176471      0.764706   \n",
       "299657            1           1     0.000000       0.000000      0.777778   \n",
       "299658            0           1     0.000000       0.000000      0.588235   \n",
       "299659            0           2     0.000000       0.100000      0.650000   \n",
       "299660            0           1     0.235294       0.000000      0.823529   \n",
       "\n",
       "        entropy_norm  \n",
       "0           0.500000  \n",
       "1           0.375000  \n",
       "2           0.500000  \n",
       "3           0.500000  \n",
       "4           0.500000  \n",
       "...              ...  \n",
       "299656      0.210145  \n",
       "299657      0.206971  \n",
       "299658      0.189384  \n",
       "299659      0.176096  \n",
       "299660      0.219678  \n",
       "\n",
       "[299661 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51707ba2-3578-4f5c-ae2a-86b9908b3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the reverse of seq_letters\n",
    "\n",
    "def has_desc_sequence(x):\n",
    "    x = x.lower()\n",
    "    seqs = [\n",
    "        'zyxwvutsrqponmlkjihgfedcba',\n",
    "        '9876543210'\n",
    "    ]\n",
    "    for seq in seqs:\n",
    "        for i in range(len(seq)-2):\n",
    "            if seq[i:i+3] in x:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "df[\"desc_seq\"] = df[\"password\"].apply(has_desc_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b0b51d-be4d-480a-8006-9b969b5d7eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc_seq\n",
       "0    294124\n",
       "1      5537\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['desc_seq'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c3030d-c564-4e12-b45d-70ec056097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detecting use of year in password (e.g. adams2010)\n",
    "#function returns an int of bool i.e. 0 or 1, depending if 19xx or 20xx matches in string x\n",
    "def has_year(x):\n",
    "    return int(bool(re.search(r'(19|20)\\d{2}', x)))\n",
    "\n",
    "df[\"has_year\"] = df[\"password\"].apply(has_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "497d5ba4-4499-4109-8d63-feb8cebc826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if it worked\n",
    "year_having_pass = df[df['has_year']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c46e965-b133-4652-89e3-63331bc8cfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>password</th>\n",
       "      <th>length</th>\n",
       "      <th>bucket</th>\n",
       "      <th>strength</th>\n",
       "      <th>lowercase_count</th>\n",
       "      <th>uppercase_count</th>\n",
       "      <th>special_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>has_special</th>\n",
       "      <th>...</th>\n",
       "      <th>char_diversity</th>\n",
       "      <th>entropy</th>\n",
       "      <th>seq_letters</th>\n",
       "      <th>max_repeat</th>\n",
       "      <th>digit_ratio</th>\n",
       "      <th>special_ratio</th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>entropy_norm</th>\n",
       "      <th>desc_seq</th>\n",
       "      <th>has_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>1903</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>335</td>\n",
       "      <td>1980</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>423</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>443</td>\n",
       "      <td>1901</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>692</td>\n",
       "      <td>2066</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299620</th>\n",
       "      <td>299959</td>\n",
       "      <td>zapatosnegros1979</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.616875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.212757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299628</th>\n",
       "      <td>299967</td>\n",
       "      <td>masonandaustin1978</td>\n",
       "      <td>18</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.530493</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.196139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299635</th>\n",
       "      <td>299974</td>\n",
       "      <td>yoselyn2059031789</td>\n",
       "      <td>17</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.734522</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.219678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299646</th>\n",
       "      <td>299985</td>\n",
       "      <td>ngoomnohangoomnoha202010</td>\n",
       "      <td>24</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.990602</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.124608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299650</th>\n",
       "      <td>299989</td>\n",
       "      <td>Sillychick12172006</td>\n",
       "      <td>18</td>\n",
       "      <td>17+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.503258</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.194625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20345 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                  password  length bucket  strength  \\\n",
       "74              74                      1903       4    0-4       0.0   \n",
       "334            335                      1980       4    0-4       0.0   \n",
       "421            423                      2021       4    0-4       1.0   \n",
       "441            443                      1901       4    0-4       0.0   \n",
       "690            692                      2066       4    0-4       1.0   \n",
       "...            ...                       ...     ...    ...       ...   \n",
       "299620      299959         zapatosnegros1979      17    17+       4.0   \n",
       "299628      299967        masonandaustin1978      18    17+       4.0   \n",
       "299635      299974         yoselyn2059031789      17    17+       4.0   \n",
       "299646      299985  ngoomnohangoomnoha202010      24    17+       4.0   \n",
       "299650      299989        Sillychick12172006      18    17+       4.0   \n",
       "\n",
       "        lowercase_count  uppercase_count  special_count  digit_count  \\\n",
       "74                    0                0              0            4   \n",
       "334                   0                0              0            4   \n",
       "421                   0                0              0            4   \n",
       "441                   0                0              0            4   \n",
       "690                   0                0              0            4   \n",
       "...                 ...              ...            ...          ...   \n",
       "299620               13                0              0            4   \n",
       "299628               14                0              0            4   \n",
       "299635                7                0              0           10   \n",
       "299646               18                0              0            6   \n",
       "299650                9                1              0            8   \n",
       "\n",
       "        has_special  ...  char_diversity   entropy  seq_letters  max_repeat  \\\n",
       "74                0  ...               0  2.000000            0           1   \n",
       "334               0  ...               0  2.000000            0           1   \n",
       "421               0  ...               0  1.500000            0           1   \n",
       "441               0  ...               0  1.500000            0           1   \n",
       "690               0  ...               0  1.500000            0           2   \n",
       "...             ...  ...             ...       ...          ...         ...   \n",
       "299620            0  ...               2  3.616875            0           1   \n",
       "299628            0  ...               2  3.530493            0           1   \n",
       "299635            0  ...               2  3.734522            1           1   \n",
       "299646            0  ...               2  2.990602            1           2   \n",
       "299650            0  ...               3  3.503258            0           2   \n",
       "\n",
       "        digit_ratio  special_ratio  unique_ratio  entropy_norm  desc_seq  \\\n",
       "74         1.000000            0.0      1.000000      0.500000         0   \n",
       "334        1.000000            0.0      1.000000      0.500000         0   \n",
       "421        1.000000            0.0      0.750000      0.375000         0   \n",
       "441        1.000000            0.0      0.750000      0.375000         0   \n",
       "690        1.000000            0.0      0.750000      0.375000         0   \n",
       "...             ...            ...           ...           ...       ...   \n",
       "299620     0.235294            0.0      0.764706      0.212757         0   \n",
       "299628     0.222222            0.0      0.722222      0.196139         0   \n",
       "299635     0.588235            0.0      0.823529      0.219678         0   \n",
       "299646     0.250000            0.0      0.375000      0.124608         0   \n",
       "299650     0.444444            0.0      0.666667      0.194625         0   \n",
       "\n",
       "        has_year  \n",
       "74             1  \n",
       "334            1  \n",
       "421            1  \n",
       "441            1  \n",
       "690            1  \n",
       "...          ...  \n",
       "299620         1  \n",
       "299628         1  \n",
       "299635         1  \n",
       "299646         1  \n",
       "299650         1  \n",
       "\n",
       "[20345 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_having_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dad0fc07-5652-433c-b0a6-65adf390cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this feature is to detect the presence of sustitutes such as adams -> @d@ms\n",
    "def leet_count(x):\n",
    "    return sum(c in \"@$!0\" for c in x)\n",
    "\n",
    "df[\"leet_count\"] = df[\"password\"].apply(leet_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e98a019d-7842-4bc6-87d4-68c90b97b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this feature is added to detect passwords such as adams123, where there is a transistion of 1 (adams->1213)\n",
    "def transitions(x):\n",
    "    t = 0\n",
    "    for i in range(len(x)-1):\n",
    "        if x[i].isalpha() != x[i+1].isalpha():\n",
    "            t += 1\n",
    "    return t\n",
    "\n",
    "df[\"transitions\"] = df[\"password\"].apply(transitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b9cdaf5-ef99-43b6-a003-da36d7ff91f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299661 entries, 0 to 299660\n",
      "Data columns (total 24 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   Unnamed: 0       299661 non-null  int64  \n",
      " 1   password         299661 non-null  object \n",
      " 2   length           299661 non-null  int64  \n",
      " 3   bucket           299661 non-null  object \n",
      " 4   strength         299661 non-null  float64\n",
      " 5   lowercase_count  299661 non-null  int64  \n",
      " 6   uppercase_count  299661 non-null  int64  \n",
      " 7   special_count    299661 non-null  int64  \n",
      " 8   digit_count      299661 non-null  int64  \n",
      " 9   has_special      299661 non-null  int64  \n",
      " 10  has_digit        299661 non-null  int64  \n",
      " 11  unique_chars     299661 non-null  int64  \n",
      " 12  char_diversity   299661 non-null  int64  \n",
      " 13  entropy          299661 non-null  float64\n",
      " 14  seq_letters      299661 non-null  int64  \n",
      " 15  max_repeat       299661 non-null  int64  \n",
      " 16  digit_ratio      299661 non-null  float64\n",
      " 17  special_ratio    299661 non-null  float64\n",
      " 18  unique_ratio     299661 non-null  float64\n",
      " 19  entropy_norm     299661 non-null  float64\n",
      " 20  desc_seq         299661 non-null  int64  \n",
      " 21  has_year         299661 non-null  int64  \n",
      " 22  leet_count       299661 non-null  int64  \n",
      " 23  transitions      299661 non-null  int64  \n",
      "dtypes: float64(6), int64(16), object(2)\n",
      "memory usage: 54.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e519792",
   "metadata": {},
   "source": [
    "## saving file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f1c8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"E:\\major_project\\datasets\\training_ready_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfd5b5-80bd-47e2-8fc6-b5e2b1d3a844",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eddfafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading file\n",
    "clean_df = pd.read_csv(r\"E:\\major_project\\datasets\\training_ready_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2ebcede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299661 entries, 0 to 299660\n",
      "Data columns (total 24 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   Unnamed: 0       299661 non-null  int64  \n",
      " 1   password         299661 non-null  object \n",
      " 2   length           299661 non-null  int64  \n",
      " 3   bucket           299661 non-null  object \n",
      " 4   strength         299661 non-null  float64\n",
      " 5   lowercase_count  299661 non-null  int64  \n",
      " 6   uppercase_count  299661 non-null  int64  \n",
      " 7   special_count    299661 non-null  int64  \n",
      " 8   digit_count      299661 non-null  int64  \n",
      " 9   has_special      299661 non-null  int64  \n",
      " 10  has_digit        299661 non-null  int64  \n",
      " 11  unique_chars     299661 non-null  int64  \n",
      " 12  char_diversity   299661 non-null  int64  \n",
      " 13  entropy          299661 non-null  float64\n",
      " 14  seq_letters      299661 non-null  int64  \n",
      " 15  max_repeat       299661 non-null  int64  \n",
      " 16  digit_ratio      299661 non-null  float64\n",
      " 17  special_ratio    299661 non-null  float64\n",
      " 18  unique_ratio     299661 non-null  float64\n",
      " 19  entropy_norm     299661 non-null  float64\n",
      " 20  desc_seq         299661 non-null  int64  \n",
      " 21  has_year         299661 non-null  int64  \n",
      " 22  leet_count       299661 non-null  int64  \n",
      " 23  transitions      299661 non-null  int64  \n",
      "dtypes: float64(6), int64(16), object(2)\n",
      "memory usage: 54.9+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974e4e62-0673-4e1a-b02c-812214467f91",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6dad6fc-9337-4e19-93da-5a723334f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "508cf13f-340c-42bb-bbb8-52683dafecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.loc[:, ~clean_df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c6ed8ac-e15e-460b-826a-1e484ba5fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = clean_df['strength'].astype(int)\n",
    "\n",
    "# features (drop non-numeric + target)\n",
    "X = clean_df.drop(columns=['password', 'bucket', 'strength'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18bc8f88-c8c1-48c9-be03-a537ca07d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data before scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2, # this is to split 20% data for testing\n",
    "    random_state=42,\n",
    "    stratify=y   # this is for class imbalance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d39ccae-a392-4ec1-a843-ea732d708e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e8ce9bb-a48c-44a4-96c7-fa654295bd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.60      0.74       551\n",
      "           1       0.85      0.60      0.71     20525\n",
      "           2       0.66      0.72      0.69     19635\n",
      "           3       0.55      0.72      0.62     12758\n",
      "           4       0.68      0.75      0.71      6464\n",
      "\n",
      "    accuracy                           0.68     59933\n",
      "   macro avg       0.74      0.68      0.69     59933\n",
      "weighted avg       0.71      0.68      0.68     59933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2efb78fc-9bc9-4912-ac16-d1b2bdadbc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a18f5a-ca2b-4029-b793-a5c8ce2f5b19",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be7d9b72-312b-4b67-9351-e8c3d383e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Initializing the model\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,    \n",
    "    max_depth=6,          \n",
    "    objective='multi:softmax', \n",
    "    num_class=5,          # 0, 1, 2, 3, 4\n",
    "    random_state=42,\n",
    "    tree_method='hist',   # Fast histogram-based method\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fitting the model with weights\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b8fc363-670f-426d-9973-216ca969019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.60      0.75       551\n",
      "           1       0.90      0.57      0.70     20525\n",
      "           2       0.68      0.71      0.69     19635\n",
      "           3       0.53      0.80      0.64     12758\n",
      "           4       0.70      0.77      0.73      6464\n",
      "\n",
      "    accuracy                           0.69     59933\n",
      "   macro avg       0.76      0.69      0.70     59933\n",
      "weighted avg       0.73      0.69      0.69     59933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a7592-5481-4e49-9839-c03aa53a16f3",
   "metadata": {},
   "source": [
    "Now, we will start with the tuning of the model. For this, we will put a baseline model first, which will act as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8edb080-5fa1-4f28-b1b7-c7090b471f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "METRIC = 'macro'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d891878",
   "metadata": {},
   "source": [
    "## baseline XGBoost model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "262524d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strength\n",
       "1    0.342460\n",
       "2    0.327614\n",
       "3    0.212871\n",
       "4    0.107859\n",
       "0    0.009197\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking class distribution in strength\n",
    "y.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab664b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline configuration\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "baseline = XGBClassifier(\n",
    "    objective=\"multi:softprob\",  #multi-class classification\n",
    "    num_class = y.nunique(),      #since values are 0,1,2,3,4\n",
    "    eval_metric= \"mlogloss\",   #calculating log loss\n",
    "    tree_method=\"hist\",         #this results in faster training\n",
    "    random_state=42,        #for reproducibility\n",
    "    n_estimators = 100   #no of trees\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e5d4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1 scores: [0.71101585 0.71477515 0.70835422 0.71144347 0.71038269]\n",
      "Mean Macro-F1: 0.7111942756401008\n",
      "Std: 0.002080439288071779\n"
     ]
    }
   ],
   "source": [
    "#for corss validation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    baseline,  #name of model\n",
    "    X,         #the features\n",
    "    y,         #the target\n",
    "    scoring=\"f1_macro\",   #metric to be evaluated\n",
    "    cv=cv, # cross-validation strategy\n",
    "    n_jobs=-1  #uses computers all processors\n",
    ")\n",
    "\n",
    "print(\"Macro-F1 scores:\", scores)\n",
    "print(\"Mean Macro-F1:\", scores.mean())\n",
    "print(\"Std:\", scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55b38d",
   "metadata": {},
   "source": [
    "From the score, we observe that the macro avg is at 71%, with a very low std of 0.002, which means the model is stable. Now, we move to wards tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a7aa8",
   "metadata": {},
   "source": [
    "The first step in tuning is controlling the rate of learning of the trees in the model. This is done using two parameters : no. of trees controlled by n-estimators, and the learning rate. \n",
    "The main objective here is to smooth the learning pattern. While looking at the mathemtical objective function, we see that gradient tells the magnitude and direction, while hessian tells the curvature of the slope. So basically, we want to go towards the least error path, while slowing down on sudden curvatures, which the xgboost model does.\n",
    "So by using a low learning rate and large no. of trees, we ensure the smoothness by taking small steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56bd27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y, # to maintain class distribution\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac22e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-mlogloss:1.48253\n",
      "[50]\tval-mlogloss:0.75793\n",
      "[100]\tval-mlogloss:0.67654\n",
      "[150]\tval-mlogloss:0.65641\n",
      "[200]\tval-mlogloss:0.64900\n",
      "[250]\tval-mlogloss:0.64558\n",
      "[300]\tval-mlogloss:0.64343\n",
      "[350]\tval-mlogloss:0.64208\n",
      "[400]\tval-mlogloss:0.64112\n",
      "[450]\tval-mlogloss:0.64043\n",
      "[500]\tval-mlogloss:0.64006\n",
      "[550]\tval-mlogloss:0.63981\n",
      "[600]\tval-mlogloss:0.63963\n",
      "[650]\tval-mlogloss:0.63947\n",
      "[700]\tval-mlogloss:0.63944\n",
      "[750]\tval-mlogloss:0.63945\n",
      "[763]\tval-mlogloss:0.63947\n",
      "Best iteration: 713\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": y.nunique(),\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,  #maximum number of boosting rounds\n",
    "    evals=[(dval, \"val\")],\n",
    "    early_stopping_rounds=50,  #stop if no improvement in 50 rounds then stops\n",
    "    verbose_eval=50  #print log every 50 iterations\n",
    ")\n",
    "\n",
    "print(\"Best iteration:\", bst.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89cef6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1: 0.7109818000591877 ± 0.0022733434978386238\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "lr_locked = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=y.nunique(),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=713,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    lr_locked,\n",
    "    X, y,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Macro-F1:\", scores.mean(), \"±\", scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b7db1",
   "metadata": {},
   "source": [
    "There has been little to no improvement with tuning learning rate. So instead, we will try to balance the class weight (instead of unbalanced) and again calculate the macro averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd38927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Password Project)",
   "language": "python",
   "name": "password_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
